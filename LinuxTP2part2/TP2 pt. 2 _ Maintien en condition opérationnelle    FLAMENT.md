# TP2 pt. 2 : Maintien en condition op√©rationnelle    FLAMENT

# Sommaire

- [TP2 pt. 2 : Maintien en condition op√©rationnelle](#tp2-pt-2--maintien-en-condition-op√©rationnelle)
- [Sommaire](#sommaire)
- [0. Pr√©requis](#0-pr√©requis)
  - [Checklist](#checklist)
- [I. Monitoring](#i-monitoring)
  - [1. Le concept](#1-le-concept)
  - [2. Setup](#2-setup)
- [II. Backup](#ii-backup)
  - [1. Intwo bwo](#1-intwo-bwo)
  - [2. Partage NFS](#2-partage-nfs)
  - [3. Backup de fichiers](#3-backup-de-fichiers)
  - [4. Unit√© de service](#4-unit√©-de-service)
    - [A. Unit√© de service](#a-unit√©-de-service)
    - [B. Timer](#b-timer)
    - [C. Contexte](#c-contexte)
  - [5. Backup de base de donn√©es](#5-backup-de-base-de-donn√©es)
  - [6. Petit point sur la backup](#6-petit-point-sur-la-backup)
- [III. Reverse Proxy](#iii-reverse-proxy)
  - [1. Introooooo](#1-introooooo)
  - [2. Setup simple](#2-setup-simple)
  - [3. Bonus HTTPS](#3-bonus-https)
- [IV. Firewalling](#iv-firewalling)
  - [1. Pr√©sentation de la syntaxe](#1-pr√©sentation-de-la-syntaxe)
  - [2. Mise en place](#2-mise-en-place)
    - [A. Base de donn√©es](#a-base-de-donn√©es)
    - [B. Serveur Web](#b-serveur-web)
    - [C. Serveur de backup](#c-serveur-de-backup)
    - [D. Reverse Proxy](#d-reverse-proxy)
    - [E. Tableau r√©cap](#e-tableau-r√©cap)

# 0. Pr√©requis

‚ûú [TP2 Part.1](../part1/README.md) termin√© : on doit avoir un NextCloud et sa base de donn√©es d√©di√©e

‚ûú Machines Rocky Linux

‚ûú Un unique host-only c√¥t√© VBox, √ßa suffira. **L'adresse du r√©seau host-only sera `10.102.1.0/24`.**

‚ûú Chaque **cr√©ation de machines** sera indiqu√© par **l'emoji üñ•Ô∏è suivi du nom de la machine**

‚ûú Si je veux **un fichier dans le rendu**, il y aura l'**emoji üìÅ avec le nom du fichier voulu**. Le fichier devra √™tre livr√© tel quel dans le d√©p√¥t git, ou dans le corps du rendu Markdown si c'est lisible et correctement format√©.

## Checklist

A chaque machine d√©ploy√©e, vous **DEVREZ** v√©rifier la üìù**checklist**üìù :

- [x] IP locale, statique ou dynamique
- [x] hostname d√©fini
- [x] firewall actif, qui ne laisse passer que le strict n√©cessaire
- [x] SSH fonctionnel avec un √©change de cl√©
- [x] acc√®s Internet (une route par d√©faut, une carte NAT c'est tr√®s bien)
- [x] r√©solution de nom
  - r√©solution de noms publics, en ajoutant un DNS public √† la machine
  - r√©solution des noms du TP, √† l'aide du fichier `/etc/hosts`
- [x] monitoring (oui, toutes les machines devront √™tre surveill√©es)

# I. Monitoring

On bouge pas pour le moment niveau machines :

| Machine         | IP            | Service                 | Port ouvert | IPs autoris√©es |
|-----------------|---------------|-------------------------|-------------|---------------|
| `web.tp2.linux` | `10.102.1.11` | Serveur Web             | 80           | *             |
| `db.tp2.linux`  | `10.102.1.12` | Serveur Base de Donn√©es | 3306           | 10.102.1.11             |

## 1. Le concept

[...]

## 2. Setup

De nombreuses solutions de monitoring existent sur le march√©. Nous, on va utiliser [Netdata](https://www.netdata.cloud/).  

Maintenant, vous √™tes des techs. Alors la page qui vous int√©resse encore plus, c'est [le d√©p√¥t git de la solution](https://github.com/netdata/netdata).

- le README.md y est souvent tr√®s complet
- pr√©sente la solution, et les √©tapes d'install
- fournit les liens vers la doc

üåû **Setup Netdata**

- y'a plein de m√©thodes d'install pour Netdata
- on va aller au plus simple, ex√©cutez, sur toutes les machines que vous souhaitez monitorer :

```bash
# Passez en root pour cette op√©ration
$ sudo su -

# Install de Netdata via le script officiel statique
$ bash <(curl -Ss https://my-netdata.io/kickstart-static64.sh)

# Quittez la session de root
$ exit
```

üåû **Manipulation du *service* Netdata**

- un *service* `netdata` a √©t√© cr√©√©
- d√©terminer s'il est actif, et s'il est param√©tr√© pour d√©marrer au boot de la machine
  - si ce n'est pas le cas, faites en sorte qu'il d√©marre au boot de la machine
  
          #Le service est-il actif:
          [tarto@web ~]$ sudo systemctl status netdata
        ‚óè netdata.service - Real time performance monitoring
           Loaded: loaded (/usr/lib/systemd/system/netdata.service; enabled; vendor preset: disabled)
           Active: active (running) since Mon 2021-10-11 10:32:41 CEST; 17min ago
           [...]
           ------------------------------------------------------------------------------------------
           [tarto@db ~]$ sudo systemctl status netdata
        ‚óè netdata.service - Real time performance monitoring
           Loaded: loaded (/usr/lib/systemd/system/netdata.service; enabled; vendor preset: disabled)
           Active: active (running) since Mon 2021-10-11 10:32:41 CEST; 17min ago
           [...]
           ------------------------------------------------------------------------------------------
           #Le service est-il param√©tr√© pour d√©marrer au boot de la machine:
            [tarto@web ~]$ sudo systemctl is-enabled netdata
            enabled
            [tarto@db ~]$ sudo systemctl is-enabled netdata
            enabled
           
- d√©terminer √† l'aide d'une commande `ss` sur quel port Netdata √©coute

        [tarto@web ~]$ ss -ltn | grep 19999
        LISTEN 0      128          0.0.0.0:19999      0.0.0.0:*
        LISTEN 0      128             [::]:19999         [::]:*
        
        [tarto@db ~]$ ss -ltn | grep 19999
        LISTEN 0      128          0.0.0.0:19999      0.0.0.0:*
        LISTEN 0      128             [::]:19999         [::]:*
        
- autoriser ce port dans le firewall

        [tarto@web ~]$ sudo firewall-cmd --add-port=19999/tcp
        Success
        
        [tarto@db ~]$ sudo firewall-cmd --add-port=19999/tcp
        Success

**Eeeeet.... c'est tout !**, rendez-vous sur `http://IP_VM:PORT` pour acc√©der √† l'interface Web de Netdata (depuis un navigateur sur votre PC).  
**C'est sexy na ? Et c'est en temps r√©el :3**

üåû **Setup Alerting**

- ajustez la conf de Netdata pour mettre en place des alertes Discord
  - *ui ui c'est bien √ßa :* vous recevrez un message Discord quand un seul critique est atteint
- [c'est l√† que √ßa se passe dans la doc de Netdata](https://learn.netdata.cloud/docs/agent/health/notifications/discord)

        [tarto@web ~]$ sudo cat /etc/netdata/health_alarm_notify.conf
        ###############################################################################
        # sending discord notifications

        # note: multiple recipients can be given like this:
        #                  "CHANNEL1 CHANNEL2 ..."

        # enable/disable sending discord notifications
        SEND_DISCORD="YES"

        # Create a webhook by following the official documentation -
        # https://support.discordapp.com/hc/en-us/articles/228383668-Intro-to-Webhooks
        DISCORD_WEBHOOK_URL="https://discord.com/api/webhooks/897037085574324244/UBZahljDhBTi-5S7EFyObPEVSWC-ItNmUTg-j4akC0r_0IczhPnBr8JaFbAhGFPpOlCF"

        # if a role's recipients are not configured, a notification will be send to
        # this discord channel (empty = do not send a notification for unconfigured
        # roles):
        DEFAULT_RECIPIENT_DISCORD="alarms"

- v√©rifiez le bon fonctionnement de l'alerting sur Discord

        sudo bash -x /usr/libexec/netdata/plugins.d/alarm-notify.sh test "sysadmin"

üåû **Config alerting**

- cr√©ez une nouvelle alerte pour recevoir une alerte √† 50% de remplissage de la RAM
- testez que votre alerte fonctionne
  - il faudra remplir artificiellement la RAM pour voir si l'alerte remonte correctement
  - sur Linux, on utilise la commande `stress` pour √ßa

        [tarto@web ~]$ stress --vm 2 --timeout 120#R√©sultat

    -    R√©sultat:
![](https://i.imgur.com/A0kOeBc.png)

![[stress test](./pics/stress-test.jpg)](https://gitlab.com/it4lik/b2-linux-2021/-/raw/main/tp/2/part2/pics/stress-test.jpg)

# II. Backup

| Machine            | IP            | Service                 | Port ouvert | IPs autoris√©es |
|--------------------|---------------|-------------------------|-------------|---------------|
| `web.tp2.linux`    | `10.102.1.11` | Serveur Web             | ?           | ?             |
| `db.tp2.linux`     | `10.102.1.12` | Serveur Base de Donn√©es | ?           | ?             |
| `backup.tp2.linux` | `10.102.1.13` | Serveur de Backup (NFS) | ?           | ?             |

üñ•Ô∏è **VM `backup.tp2.linux`**

**D√©roulez la [üìù**checklist**üìù](#checklist) sur cette VM.**

## 1. Intwo bwo

[...]

## 2. Partage NFS

üåû **Setup environnement**

- cr√©er un dossier `/srv/backup/`
- il contiendra un sous-dossier ppour chaque machine du parc
  - commencez donc par cr√©er le dossier `/srv/backup/web.tp2.linux/`
- il existera un partage NFS pour chaque machine (principe du moindre privil√®ge)

üåû **Setup partage NFS**

- je crois que vous commencez √† conna√Ætre la chanson... Google "nfs server rocky linux"
  - [ce lien me semble √™tre particuli√®rement simple et concis](https://www.server-world.info/en/note?os=Rocky_Linux_8&p=nfs&f=1)

        [tarto@backup ~]]# dnf -y install nfs-utils
        [tarto@backup ~]]# vi /etc/idmapd.conf
        [...]
        Domain = backup.tp2.linux
        [...]
        
        [tarto@backup ~]]# vi /etc/exports
        # create new
        # for example, set [/home/nfsshare] as NFS share
        /svr/backup/web.tp2.linux 10.102.1.0/24(rw,no_root_squash)
        
        [tarto@backup ~]]# systemctl enable --now rpcbind nfs-server
        [tarto@backup ~]]# firewall-cmd --add-service=nfs
        success

üåû **Setup points de montage sur `web.tp2.linux`**

- [sur le m√™me site, y'a √ßa](https://www.server-world.info/en/note?os=Rocky_Linux_8&p=nfs&f=2)
- monter le dossier `/srv/backups/web.tp2.linux` du serveur NFS dans le dossier `/srv/backup/` du serveur Web
- v√©rifier...
  - avec une commande `mount` que la partition est bien mont√©e
  
        sudo mount -t nfs backup.tp2.linux:/srv/backup/web.tp2.linux /srv/backup/
          
  - avec une commande `df -h` qu'il reste de la place

        [tarto@web ~]$ df -h
        Filesystem                                  Size  Used Avail Use% Mounted on
        devtmpfs                                    892M     0  892M   0% /dev
        tmpfs                                       909M  308K  909M   1% /dev/shm
        tmpfs                                       909M  8.5M  901M   1% /run
        tmpfs                                       909M     0  909M   0% /sys/fs/cgroup
        /dev/mapper/rl-root                         6.2G  4.6G  1.7G  74% /
        /dev/sda1                                  1014M  234M  781M  24% /boot
        tmpfs                                       182M     0  182M   0% /run/user/1000
        backup.tp2.linux:/srv/backup/web.tp2.linux  6.2G  1.9G  4.4G  30% /srv/backup
        
  - avec une commande `touch` que vous avez le droit d'√©crire dans cette partition
- faites en sorte que cette partition se monte automatiquement gr√¢ce au fichier `/etc/fstab`

üåü **BONUS** : partitionnement avec LVM

- ajoutez un disque √† la VM `backup.tp2.linux`
- utilisez LVM pour cr√©er une nouvelle partition (5Go √ßa ira)
- monter automatiquement cette partition au d√©marrage du syst√®me √† l'aide du fichier `/etc/fstab`
- cette nouvelle partition devra √™tre mont√©e sur le dossier `/srv/backup/`

## 3. Backup de fichiers

**Un peu de scripting `bash` !** Le scripting est le meilleur ami de l'admin, vous allez pas y couper hihi.  

La syntaxe de `bash` est TRES particuli√®re, mais ce que je vous demande de r√©aliser l√† est un script minimaliste.

Votre script **DEVRA**...

- comporter un shebang
- comporter un commentaire en en-t√™te qui indique le but du script, en quelques mots
- comporter un commentaire qui indique l'auteur et la date d'√©criture du script

Par exemple :

```bash
#!/bin/bash
# Simple backup script
# it4 - 09/10/2021

...
```

üåû **R√©diger le script de backup `/srv/tp2_backup.sh`**

- le script cr√©e une archive compress√©e `.tar.gz` du dossier cibl√©
  - cela se fait avec la commande `tar`
- l'archive g√©n√©r√©e doit s'appeler `tp2_backup_YYMMDD_HHMMSS.tar.gz`
  - vous remplacerez √©videmment `YY` par l'ann√©e (`21`), `MM` par le mois (`10`), etc.
  - ces infos sont d√©termin√©es dynamiquement au moment o√π le script s'ex√©cute √† l'aide de la commande `date`
- le script utilise la commande `rsync` afin d'envoyer la sauvegarde dans le dossier de destination
- il **DOIT** pouvoir √™tre appel√© de la sorte :

```bash
$ ./tp2_backup.sh <DESTINATION> <DOSSIER_A_BACKUP>
```

üìÅ **Fichier `/srv/tp2_backup.sh`**

> **Il est strictement hors de question d'utiliser `sudo` dans le contenu d'un script.**  
Il est envisageable, en revanche, que le script doive √™tre lanc√© avec root ou la commande `sudo` afin d'obtenir des droits √©lev√©s pendant son ex√©cution.

üåû **Tester le bon fonctionnement**

- ex√©cuter le script sur le dossier de votre choix
- prouvez que la backup s'est bien ex√©cut√©e
- **tester de restaurer les donn√©es**
  - r√©cup√©rer l'archive g√©n√©r√©e, et v√©rifier son contenu

üåü **BONUS**

- faites en sorte que votre script ne conserve que les 5 backups les plus r√©centes apr√®s le `rsync`
- faites en sorte qu'on puisse passer autant de dossier qu'on veut au script : `./tp2_backup.sh <DESTINATION> <DOSSIER1> <DOSSIER2> <DOSSIER3>...` et n'obtenir qu'une seule archive
- utiliser [Borg](https://borgbackup.readthedocs.io/en/stable/) plut√¥t que `rsync`

## 4. Unit√© de service

Lancer le script √† la main c'est bien. **Le mettre dans une joulie *unit√© de service* et l'ex√©cuter √† intervalles r√©guliers, de mani√®re automatis√©e, c'est mieux.**

Le but va √™tre de cr√©er un *service* systemd pour que vous puissiez interagir avec votre script de sauvegarde en faisant :

```bash
$ sudo systemctl start tp2_backup
$ sudo systemctl status tp2_backup
```

Ensuite on cr√©era un *timer systemd* qui permettra de d√©clencher le lancement de ce *service* √† intervalles r√©guliers.

**La classe nan ?**

![systemd can do that](./pics/suprised-cat.jpg)

---

### A. Unit√© de service

üåû **Cr√©er une *unit√© de service*** pour notre backup

- c'est juste un fichier texte hein
- doit se trouver dans le dossier `/etc/systemd/system/`
- doit s'appeler `tp2_backup.service`
- le contenu :

```bash
[tarto@backup ~]$ cat /etc/systemd/system/tp2_backup.service
[Unit]
Description=Our own lil backup service (TP2)

[Service]
ExecStart=/srv/tp2_backup.sh /srv/backup1  /srv/backup2
Type=oneshot
RemainAfterExit=no

[Install]
WantedBy=multi-user.target
```

> Pour les tests, sauvegardez le dossier de votre choix, peu importe lequel.

üåû **Tester le bon fonctionnement**

- n'oubliez pas d'ex√©cuter `sudo systemctl daemon-reload` √† chaque ajout/modification d'un *service*
- essayez d'effectuer une sauvegarde avec `sudo systemctl start backup`
- prouvez que la backup s'est bien ex√©cut√©e
  - v√©rifiez la pr√©sence de la nouvelle archive

---

### B. Timer

Un *timer systemd* permet l'ex√©cution d'un *service* √† intervalles r√©guliers.

üåû **Cr√©er le *timer* associ√© √† notre `tp2_backup.service`**

- toujours juste un fichier texte
- dans le dossier `/etc/systemd/system/` aussi
- fichier `tp2_backup.timer`
- contenu du fichier :

```bash
[Unit]
Description=Periodically run our TP2 backup script
Requires=tp2_backup.service

[Timer]
Unit=tp2_backup.service
OnCalendar=*-*-* *:*:00

[Install]
WantedBy=timers.target
```

> Le nom du *timer* doit √™tre rigoureusement identique √† celui du *service*. Seule l'extension change : de `.service` √† `.timer`. C'est notamment gr√¢ce au nom identique que systemd sait que ce *timer* correspond √† un *service* pr√©cis.

üåû **Activez le timer**

- d√©marrer le *timer* : `sudo systemctl start tp2_backup.timer`
- activer le au d√©marrage avec une autre commande `systemctl`
- prouver que...
  - le *timer* est actif actuellement
  - qu'il est param√©tr√© pour √™tre actif d√®s que le syst√®me boot

üåû **Tests !**

- avec la ligne `OnCalendar=*-*-* *:*:00`, le *timer* d√©clenche l'ex√©cution du *service* toutes les minutes
- v√©rifiez que la backup s'ex√©cute correctement

---

### C. Contexte

üåû **Faites en sorte que...**

- votre backup s'ex√©cute sur la machine `web.tp2.linux`
- le dossier sauvegard√© est celui qui contient le site NextCloud (quelque part dans `/var/`)
- la destination est le dossier NFS mont√© depuis le serveur `backup.tp2.linux`
- la sauvegarde s'ex√©cute tous les jours √† 03h15 du matin
- prouvez avec la commande `sudo systemctl list-timers` que votre *service* va bien s'ex√©cuter la prochaine fois qu'il sera 03h15

üìÅ **Fichier `/etc/systemd/system/tp2_backup.timer`**  
üìÅ **Fichier `/etc/systemd/system/tp2_backup.service`**

## 5. Backup de base de donn√©es

Sauvegarder des dossiers c'est bien. Mais sauvegarder aussi les bases de donn√©es c'est mieux.

üåû **Cr√©ation d'un script `/srv/tp2_backup_db.sh`**

- il utilise la commande `mysqldump` pour r√©cup√©rer les donn√©es de la base de donn√©es
- cela g√©n√®re un fichier `.sql` qui doit ensuite √™tre compress√© en `.tar.gz`
- il s'ex√©cute sur la machine `db.tp2.linux`
- il s'utilise de la fa√ßon suivante :

```bash
$ ./tp2_backup_db.sh <DESTINATION> <DATABASE>
```

üìÅ **Fichier `/srv/tp2_backup_db.sh`**  

üåû **Restauration**

- tester la restauration de donn√©es
- c'est √† dire, une fois la sauvegarde effectu√©e, et le `tar.gz` en votre possession, tester que vous √™tes capables de restaurer la base dans l'√©tat au moment de la sauvegarde
  - il faut r√©injecter le fichier `.sql` dans la base √† l'aide d'une commmande `mysql`

üåû ***Unit√© de service***

- pareil que pour la sauvegarde des fichiers ! On va faire de ce script une *unit√© de service*.
- votre script `/srv/tp2_backup_db.sh` doit pouvoir se lancer gr√¢ce √† un *service* `tp2_backup_db.service`
- le *service* est ex√©cut√© tous les jours √† 03h30 gr√¢ce au *timer* `tp2_backup_db.timer`
- prouvez le bon fonctionnement du *service* ET du *timer*

üìÅ **Fichier `/etc/systemd/system/tp2_backup_db.timer`**  
üìÅ **Fichier `/etc/systemd/system/tp2_backup_db.service`**

## 6. Petit point sur la backup

A ce stade vous avez :

- un script qui tourne sur `web.tp2.linux` et qui **sauvegarde les fichiers de NextCloud**
- un script qui tourne sur `db.tp2.linux` et qui **sauvegarde la base de donn√©es de NextCloud**
- toutes **les backups sont centralis√©es** sur `backup.tp2.linux`
- **tout est g√©r√© de fa√ßon automatis√©e**
  - les scripts sont packag√©s dans des *services*
  - les services sont d√©clench√©s par des *timers*
  - tout est param√©tr√© pour s'allumer quand les machines boot (les *timers* comme le serveur NFS)

üî•üî• **That is clean shit.** üî•üî•

# III. Reverse Proxy

## 1. Introooooo

Un *reverse proxy* est un outil qui sert d'interm√©diaire entre le client et un serveur donn√© (souvent un serveur Web).

**C'est l'admin qui le met en place, afin de prot√©ger l'acc√®s au serveur Web.**

Une fois en place, le client devra saisir l'IP (ou le nom) du *reverse proxy* pour acc√©der √† l'application Web (ce ne sera plus directement l'IP du serveur Web).

Un *reverse proxy* peut permettre plusieurs choses :

- chiffrement
  - c'est lui qui mettra le HTTPS en place (protocole HTTP + chiffrement avec le protocole TLS)
  - on pourrait le faire directement avec le serveur Web (Apache) dans notre cas
  - pour de meilleures performances, il est pr√©f√©rable de d√©dier une machine au chiffrement HTTPS, et de laisser au serveur web un unique job : traiter les requ√™tes HTTP
- r√©partition de charge
  - plut√¥t qu'avoir un seul serveur Web, on peut en setup plusieurs
  - ils h√©bergent tous la m√™me application
  - le *reverse proxy* enverra les clients sur l'un ou l'autre des serveurs Web, afin de r√©partir la charge √† traiter
- d'autres trucs
  - caching de ressources statiques (CSS, JSS, images, etc.)
  - tol√©rance de pannes
  - ...

---

**Dans ce TP on va setup un reverse proxy NGINX tr√®s simpliste.**

![Apache at the back hihi](./pics/nginx-at-the-front-apache-at-the-back.jpg)

## 2. Setup simple

| Machine            | IP            | Service                 | Port ouvert | IPs autoris√©es |
|--------------------|---------------|-------------------------|-------------|---------------|
| `web.tp2.linux`    | `10.102.1.11` | Serveur Web             | ?           | ?             |
| `db.tp2.linux`     | `10.102.1.12` | Serveur Base de Donn√©es | ?           | ?             |
| `backup.tp2.linux` | `10.102.1.13` | Serveur de Backup (NFS) | ?           | ?             |
| `front.tp2.linux`  | `10.102.1.14` | Reverse Proxy           | ?           | ?             |

üñ•Ô∏è **VM `front.tp2.linu`x**

**D√©roulez la [üìù**checklist**üìù](#checklist) sur cette VM.**

üåû **Installer NGINX**

- vous devrez d'abord installer le paquet `epel-release` avant d'installer `nginx`
  - EPEL c'est des d√©p√¥ts additionnels pour Rocky
  - NGINX n'est pas pr√©sent dans les d√©p√¥ts par d√©faut que conna√Æt Rocky
- le fichier de conf principal de NGINX est `/etc/nginx/nginx.conf`

```
[tarto@front ~]$ sudo dnf install epel-release nginx
```

üåû **Tester !**

- lancer le *service* `nginx`
- le param√©trer pour qu'il d√©marre seul quand le syst√®me boot
- rep√©rer le port qu'utilise NGINX par d√©faut, pour l'ouvrir dans le firewall
- v√©rifier que vous pouvez joindre NGINX avec une commande `curl` depuis votre PC

```
[tarto@front ~]$ sudo systemctl start nginx
[tarto@front ~]$ sudo systemctl is-active nginx
active
[tarto@front ~]$ sudo systemctl enable nginx
Created symlink /etc/systemd/system/multi-user.target.wants/nginx.service ‚Üí /usr/lib/systemd/system/nginx.service.
[tarto@front ~]$ sudo systemctl is-enabled nginx
enabled

[tarto@front ~]$ sudo ss -lpnt
State  Recv-Q  Send-Q   Local Address:Port   Peer Address:Port Process
LISTEN 0       128            0.0.0.0:80          0.0.0.0:*     users:(("nginx",pid=3756,fd=8),("nginx",pid=3755,fd=8))
LISTEN 0       128               [::]:80             [::]:*     users:(("nginx",pid=3756,fd=9),("nginx",pid=3755,fd=9))
[tarto@front ~]$ sudo firewall-cmd --add-port 80/tcp
success

C:\Users\mattf>curl 10.102.1.14:80
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
  <head>
    <title>Test Page for the Nginx HTTP Server on Rocky Linux</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <style type="text/css">
    [...]
```

üåû **Explorer la conf par d√©faut de NGINX**

- rep√©rez l'utilisateur qu'utilise NGINX par d√©faut

```
[tarto@front ~]$ sudo cat /etc/nginx/nginx.conf
# For more information on configuration, see:
#   * Official English Documentation: http://nginx.org/en/docs/
#   * Official Russian Documentation: http://nginx.org/ru/docs/

user nginx;
```
- dans la conf NGINX, on utilise le mot-cl√© `server` pour ajouter un nouveau site
  - rep√©rez le bloc `server {}` dans le fichier de conf principal

```
[tarto@front ~]$ sudo cat /etc/nginx/nginx.conf
 server {
        listen       80 default_server;
        listen       [::]:80 default_server;
        server_name  _;
        root         /usr/share/nginx/html;

        # Load configuration files for the default server block.
        include /etc/nginx/default.d/*.conf;

        location / {
        }

        error_page 404 /404.html;
            location = /40x.html {
        }

        error_page 500 502 503 504 /50x.html;
            location = /50x.html {
        }
    }
```
- par d√©faut, le fichier de conf principal inclut d'autres fichiers de conf
  - mettez en √©vidence ces lignes d'inclusion dans le fichier de conf principal

```
[tarto@front ~]$ sudo cat /etc/nginx/nginx.conf
# Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.
include /usr/share/nginx/modules/*.conf;
```

üåû **Modifier la conf de NGINX**

- pour que √ßa fonctionne, le fichier `/etc/hosts` de la machine **DOIT** √™tre rempli correctement, conform√©ment √† la **[üìù**checklist**üìù](#checklist)**

```
[tarto@front ~]$ sudo cat /etc/hosts
10.102.1.11 web.tp2.linux
10.102.1.12 db.tp2.linux
10.102.1.13 backup.tp2.linux
```
- supprimer le bloc `server {}` par d√©faut, pour ne plus pr√©senter la page d'accueil NGINX

```
[tarto@front ~]$ sudo cat /etc/nginx/nginx.conf
# For more information on configuration, see:
#   * Official English Documentation: http://nginx.org/en/docs/
#   * Official Russian Documentation: http://nginx.org/ru/docs/

user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log;
pid /run/nginx.pid;

# Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.
include /usr/share/nginx/modules/*.conf;

events {
    worker_connections 1024;
}

http {
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;

    sendfile            on;
    tcp_nopush          on;
    tcp_nodelay         on;
    keepalive_timeout   65;
    types_hash_max_size 2048;

    include             /etc/nginx/mime.types;
    default_type        application/octet-stream;

    # Load modular configuration files from the /etc/nginx/conf.d directory.
    # See http://nginx.org/en/docs/ngx_core_module.html#include
    # for more information.
    include /etc/nginx/conf.d/*.conf;
```
- cr√©er un fichier `/etc/nginx/conf.d/web.tp2.linux.conf` avec le contenu suivant :
  - j'ai sur-comment√© pour vous expliquer les lignes, n'h√©sitez pas √† d√©gommer mes lignes de commentaires

```bash
[tarto@front ~]$ sudo cat /etc/nginx/conf.d/web.tp2.linux.conf
server {
    listen 80;
    server_name web.tp2.linux;
    location / {

        proxy_pass http://web.tp2.linux;
    }
}
```

# IV. Firewalling

**On va rendre nos firewalls un peu plus agressifs.**

Actuellement je vous ai juste demand√© d'autoriser le trafic sur tel ou tel port. C'est bien.

**Maintenant on va restreindre le trafic niveau IP aussi.**

Par exemple : notre base de donn√©es `db.tp2.linux` n'est acc√©d√©e que par le serveur Web `web.tp2.linux`, et par aucune autre machine.  
On va donc configurer le firewall de la base de donn√©es pour qu'elle n'accepte QUE le trafic qui vient du serveur Web.

**On va *harden* ("durcir" en fran√ßais) la configuration de nos firewalls.**

## 1. Pr√©sentation de la syntaxe

[...]

## 2. Mise en place

### A. Base de donn√©es

üåû **Restreindre l'acc√®s √† la base de donn√©es `db.tp2.linux`**

- seul le serveur Web doit pouvoir joindre la base de donn√©es sur le port 3306/tcp
- vous devez aussi autoriser votre acc√®s SSH
- n'h√©sitez pas √† multiplier les zones (une zone `ssh` et une zone `db` par exemple)

```
[tarto@db ~]$ sudo firewall-cmd --set-default-zone=drop
success
[tarto@db ~]$ sudo firewall-cmd --new-zone=web --permanent
success
[tarto@db ~]$ sudo firewall-cmd --zone=web --add-source=10.102.1.11/24 --permanent
success
[tarto@db ~]$ sudo firewall-cmd --zone=web --add-port=3306/tcp --permanent
success

[tarto@db ~]$ sudo firewall-cmd --new-zone=ssh --permanent
success
[tarto@db ~]$ sudo firewall-cmd --zone=ssh --add-source=10.102.1.1/24 --permanent
success
[tarto@db ~]$ sudo firewall-cmd --zone=ssh --add-port=22/tcp --permanent
success
```

> Quand vous faites une connexion SSH, vous la faites sur l'interface Host-Only des VMs. Cette interface est branch√©e √† un Switch qui porte le nom du Host-Only. Pour rappel, votre PC a aussi une interface branch√©e √† ce Switch Host-Only.  
C'est depuis cette IP que la VM voit votre connexion. C'est cette IP que vous devez autoriser dans le firewall de votre VM pour SSH.

üåû **Montrez le r√©sultat de votre conf avec une ou plusieurs commandes `firewall-cmd`**

- `sudo firewall-cmd --get-active-zones`
- `sudo firewall-cmd --get-default-zone`
- `sudo firewall-cmd --list-all --zone=?`

```
[tarto@db ~]$ sudo firewall-cmd --get-active-zones
drop
  interfaces: enp0s3 enp0s8
ssh
  sources: 10.102.1.1/24
web
  sources: 10.102.1.11/24
  
[tarto@db ~]$ sudo firewall-cmd --get-default-zone
drop

[tarto@db ~]$ sudo firewall-cmd --list-all --zone=web
web (active)
  target: default
  icmp-block-inversion: no
  interfaces:
  sources: 10.102.1.11/24
  services:
  ports: 3306/tcp
  protocols:
  masquerade: no
  forward-ports:
  source-ports:
  icmp-blocks:
  rich rules:
  
[tarto@db ~]$ sudo firewall-cmd --list-all --zone=ssh
ssh (active)
  target: default
  icmp-block-inversion: no
  interfaces:
  sources: 10.102.1.1/24
  services:
  ports: 22/tcp
  protocols:
  masquerade: no
  forward-ports:
  source-ports:
  icmp-blocks:
  rich rules:
  
[tarto@db ~]$ sudo firewall-cmd --list-all --zone=drop
drop (active)
  target: DROP
  icmp-block-inversion: no
  interfaces: enp0s3 enp0s8
  sources:
  services:
  ports:
  protocols:
  masquerade: no
  forward-ports:
  source-ports:
  icmp-blocks:
  rich rules:
```

### B. Serveur Web

üåû **Restreindre l'acc√®s au serveur Web `web.tp2.linux`**

- seul le reverse proxy `front.tp2.linux` doit acc√©der au serveur web sur le port 80
- n'oubliez pas votre acc√®s SSH

```
[tarto@web ~]$ sudo firewall-cmd --set-default-zone=drop
success
[tarto@web ~]$ sudo firewall-cmd --new-zone=proxy --permanent
success
[tarto@web ~]$ sudo firewall-cmd --zone=proxy --add-source=10.102.1.14/24 --permanent
success
[tarto@web ~]$ sudo firewall-cmd --zone=proxy --add-port=80/tcp --permanent
success

[tarto@web ~]$ sudo firewall-cmd --new-zone=ssh --permanent
success
[tarto@web ~]$ sudo firewall-cmd --zone=ssh --add-source=10.102.1.1/24 --permanent
success
[tarto@web ~]$ sudo firewall-cmd --zone=ssh --add-port=22/tcp --permanent
success
```

üåû **Montrez le r√©sultat de votre conf avec une ou plusieurs commandes `firewall-cmd`**

```
[tarto@web ~]$ sudo firewall-cmd --get-active-zones
drop
  interfaces: enp0s3 enp0s8
proxy
  sources: 10.102.1.14/24
ssh
  sources: 10.102.1.1/24
  
[tarto@web ~]$ sudo firewall-cmd --get-default-zone
drop

[tarto@web ~]$ sudo firewall-cmd --list-all --zone=proxy
proxy (active)
  target: default
  icmp-block-inversion: no
  interfaces:
  sources: 10.102.1.14/24
  services:
  ports: 80/tcp
  protocols:
  masquerade: no
  forward-ports:
  source-ports:
  icmp-blocks:
  rich rules:

[tarto@web ~]$ sudo firewall-cmd --list-all --zone=ssh
ssh (active)
  target: default
  icmp-block-inversion: no
  interfaces:
  sources: 10.102.1.1/24
  services:
  ports: 22/tcp
  protocols:
  masquerade: no
  forward-ports:
  source-ports:
  icmp-blocks:
  rich rules:

[tarto@web ~]$ sudo firewall-cmd --list-all --zone=drop
drop (active)
  target: DROP
  icmp-block-inversion: no
  interfaces: enp0s3 enp0s8
  sources:
  services:
  ports:
  protocols:
  masquerade: no
  forward-ports:
  source-ports:
  icmp-blocks:
  rich rules:
```

### C. Serveur de backup

üåû **Restreindre l'acc√®s au serveur de backup `backup.tp2.linux`**

- seules les machines qui effectuent des backups doivent √™tre autoris√©es √† contacter le serveur de backup *via* NFS
- n'oubliez pas votre acc√®s SSH

```
[tarto@backup ~]$ sudo firewall-cmd --set-default-zone=drop
success
[tarto@backup ~]$ sudo firewall-cmd --new-zone=nfs --permanent
success
[tarto@backup ~]$ sudo firewall-cmd --zone=nfs --add-source=10.102.1.11/24 --permanent
success
[tarto@backup ~]$ sudo firewall-cmd --zone=nfs --add-source=10.102.1.11/22 --permanent
success

[tarto@backup ~]$ sudo firewall-cmd --new-zone=ssh --permanent
success
[tarto@backup ~]$ sudo firewall-cmd --zone=nfs --remove-port=22/tcp --permanent
success
[tarto@backup ~]$ sudo firewall-cmd --zone=ssh --add-port=22/tcp --permanent
success
```

üåû **Montrez le r√©sultat de votre conf avec une ou plusieurs commandes `firewall-cmd`**

```
[tarto@backup ~]$ sudo firewall-cmd --get-active-zones
drop
  interfaces: enp0s3 enp0s8
nfs
  sources: 10.102.1.11/24 10.102.1.12/24
ssh
  sources: 10.102.1.1/24
  
[tarto@backup ~]$ sudo firewall-cmd --get-default-zone
drop

[tarto@backup ~]$ sudo firewall-cmd --list-all --zone=nfs
nfs (active)
  target: default
  icmp-block-inversion: no
  interfaces:
  sources: 10.102.1.11/24 10.102.1.12/24
  services:
  ports:
  protocols:
  masquerade: no
  forward-ports:
  source-ports:
  icmp-blocks:
  rich rules:

[tarto@backup ~]$ sudo firewall-cmd --list-all --zone=ssh
ssh (active)
  target: default
  icmp-block-inversion: no
  interfaces:
  sources: 10.102.1.1/24
  services:
  ports: 22/tcp
  protocols:
  masquerade: no
  forward-ports:
  source-ports:
  icmp-blocks:
  rich rules:

[tarto@backup ~]$ sudo firewall-cmd --list-all --zone=drop
drop (active)
  target: DROP
  icmp-block-inversion: no
  interfaces: enp0s3 enp0s8
  sources:
  services:
  ports:
  protocols:
  masquerade: no
  forward-ports:
  source-ports:
  icmp-blocks:
  rich rules:


```

### D. Reverse Proxy

üåû **Restreindre l'acc√®s au reverse proxy `front.tp2.linux`**

- seules les machines du r√©seau `10.102.1.0/24` doivent pouvoir joindre le proxy
- n'oubliez pas votre acc√®s SSH

```
[tarto@front ~]$ sudo firewall-cmd --set-default-zone drop
success
[tarto@front ~]$ sudo firewall-cmd --new-zone=proxy --permanent
success
[tarto@front ~]$ sudo firewall-cmd --zone=proxy --add-source=10.102.1.0/24 --permanent
success
[tarto@front ~]$ sudo firewall-cmd --new-zone=ssh --permanent
success
[tarto@front ~]$ sudo firewall-cmd --zone=ssh --add-source=10.102.1.1/24 --permanent
success
[tarto@front ~]$ sudo firewall-cmd --zone=ssh --add-port=22/tcp --permanent
success
```

üåû **Montrez le r√©sultat de votre conf avec une ou plusieurs commandes `firewall-cmd`**

```
[tarto@front ~]$ sudo firewall-cmd --get-active-zones
drop
  interfaces: enp0s3 enp0s8
proxy
  sources: 10.102.1.0/24
ssh
  sources: 10.102.1.1/24
  
[tarto@front ~]$ sudo firewall-cmd --get-default-zone
drop

[tarto@front ~]$ sudo firewall-cmd --list-all --zone=proxy
proxy (active)
  target: default
  icmp-block-inversion: no
  interfaces:
  sources: 10.102.1.0/24
  services:
  ports:
  protocols:
  masquerade: no
  forward-ports:
  source-ports:
  icmp-blocks:
  rich rules:

[tarto@front ~]$ sudo firewall-cmd --list-all --zone=ssh
ssh (active)
  target: default
  icmp-block-inversion: no
  interfaces:
  sources: 10.102.1.1/24
  services:
  ports: 22/tcp
  protocols:
  masquerade: no
  forward-ports:
  source-ports:
  icmp-blocks:
  rich rules:

[tarto@front ~]$ sudo firewall-cmd --list-all --zone=drop
drop (active)
  target: DROP
  icmp-block-inversion: no
  interfaces: enp0s3 enp0s8
  sources:
  services:
  ports:
  protocols:
  masquerade: no
  forward-ports:
  source-ports:
  icmp-blocks:
  rich rules:
```

### E. Tableau r√©cap

üåû **Rendez-moi le tableau suivant, correctement rempli :**

| Machine            | IP            | Service                 | Port ouvert         | IPs autoris√©es                                    |
|--------------------|---------------|-------------------------|---------------------|---------------------------------------------------|
| `web.tp2.linux`    | `10.102.1.11` | Serveur Web             | `80/tcp` `22/tcp`   | `10.102.1.14/24` `10.102.1.1/24`                  |
| `db.tp2.linux`     | `10.102.1.12` | Serveur Base de Donn√©es | `3306/tcp` `22/tcp` | `10.102.1.11/24` `10.102.1.1/24`                  |
| `backup.tp2.linux` | `10.102.1.13` | Serveur de Backup (NFS) | `22/tcp`            | `10.102.1.11/24` `10.102.1.12/24` `10.102.1.1/32` |
| `front.tp2.linux`  | `10.102.1.14` | Reverse Proxy           | `80/tcp` `22/tcp`   | `10.102.1.0/24` `10.102.1.1/24`                   |